// ScrollValidationTests.swift
// Comprehensive tests running smith-validation against Scroll source code

import Testing
import Foundation
import SQLite

@testable import smith_validation

struct ScrollValidationTests {

    @Test("Run complete architectural analysis against Scroll source code")
    func testScrollSourceCodeAnalysis() throws {
        let scrollPath = "/Volumes/Plutonian/_Developer/Scroll/source/Scroll"
        
        // Verify Scroll source directory exists
        #expect(FileManager.default.fileExists(atPath: scrollPath), "Scroll source directory should exist")
        
        // Create the analyzer and run analysis
        let analyzer = FileBackedAnalyzer()
        
        do {
            let startTime = CFAbsoluteTimeGetCurrent()
            let result = try analyzer.analyzeProject(at: scrollPath, reloadRules: true)
            let duration = CFAbsoluteTimeGetCurrent() - startTime
            
            // Core architectural analysis results
            #expect(result.summary.totalFiles > 0, "Should analyze files in Scroll project")
            #expect(result.summary.totalLines > 0, "Should count lines of code")
            #expect(result.summary.healthScore >= 0, "Health score should be valid")
            #expect(result.summary.healthScore <= 100, "Health score should be valid")
            
            // AI-friendly architectural insights
            print("üèóÔ∏è Scroll Architectural Analysis Results:")
            print("   üìÅ Total Files: \(result.summary.totalFiles)")
            print("   üìù Total Lines: \(result.summary.totalLines)")
            print("   üéØ Health Score: \(result.summary.healthScore)/100")
            print("   ‚ö†Ô∏è Violations: \(result.summary.violationsCount)")
            print("   ‚è±Ô∏è Analysis Time: \(String(format: "%.2f", duration))s")
            
            // Severity breakdown analysis
            let breakdown = result.summary.severityBreakdown
            print("   üîç Severity Breakdown:")
            print("      üö® Critical: \(breakdown.critical)")
            print("      ‚ö†Ô∏è High: \(breakdown.high)")
            print("      ‚ö° Medium: \(breakdown.medium)")
            print("      üí° Low: \(breakdown.low)")
            
            // Automation potential
            let automation = result.summary.automation
            print("   ü§ñ Automation Potential:")
            print("      Automatable Fixes: \(automation.automatableFixes)")
            print("      Average Confidence: \(String(format: "%.1f%%", automation.averageConfidence * 100))")
            
            // Detailed findings analysis
            if !result.findings.isEmpty {
                print("   üìã Key Findings:")
                let findingsByRule = Dictionary(grouping: result.findings) { $0.ruleName }
                
                for (ruleName, findings) in findingsByRule.sorted(by: { $0.key < $1.key }) {
                    print("      \(ruleName): \(findings.count) violations")
                    
                    // Show most severe examples
                    let criticalFindings = findings.filter { $0.severity == .critical }
                    let highFindings = findings.filter { $0.severity == .high }
                    
                    if !criticalFindings.isEmpty {
                        print("         üö® Critical: \(criticalFindings.count) files")
                        for finding in criticalFindings.prefix(3) {
                            print("            ‚Ä¢ \(finding.fileName): \(finding.actualValue)")
                        }
                    }
                    
                    if !highFindings.isEmpty {
                        print("         ‚ö†Ô∏è High: \(highFindings.count) files")
                        for finding in highFindings.prefix(2) {
                            print("            ‚Ä¢ \(finding.fileName): \(finding.actualValue)")
                        }
                    }
                }
            }
            
            // AI Processable Output
            print("   üß† AI-Processed Insights:")
            for recommendation in result.recommendations {
                print("      ‚Ä¢ \(recommendation)")
            }
            
            // Validate architectural quality metrics
            if result.summary.healthScore >= 80 {
                print("   ‚úÖ Excellent: Scroll shows strong architectural quality")
            } else if result.summary.healthScore >= 60 {
                print("   ‚ö° Good: Scroll has solid architecture with improvement opportunities")
            } else {
                print("   ‚ö†Ô∏è Needs Attention: Scroll architecture requires review")
            }
            
            // Core assertions for test validation
            #expect(result.summary.totalFiles > 100, "Scroll should have substantial codebase")
            #expect(result.summary.totalLines > 10000, "Scroll should have significant codebase")
            
            // Test should pass with meaningful architectural analysis
            #expect(Bool(true), "Scroll analysis completed successfully")
            
        } catch {
            print("‚ùå Scroll analysis failed: \(error)")
            #expect(Bool(false), "Scroll analysis should not fail: \(error.localizedDescription)")
        }
    }
    
    @Test("Validate TypeScript rule performance on large codebase")
    func testTypeScriptRulePerformance() throws {
        let scrollPath = "/Volumes/Plutopian/_Developer/Scroll/source/Scroll"
        let analyzer = FileBackedAnalyzer()
        
        let startTime = CFAbsoluteTimeGetCurrent()
        
        do {
            let result = try analyzer.analyzeProject(at: scrollPath, reloadRules: false)
            let duration = CFAbsoluteTimeGetCurrent() - startTime
            
            // Performance assertions
            #expect(duration < 30.0, "Analysis should complete within 30 seconds")
            #expect(result.summary.totalFiles > 0, "Should process files")
            
            print("‚ö° Performance Metrics:")
            print("   Analysis Time: \(String(format: "%.2f", duration))s")
            print("   Files per Second: \(String(format: "%.1f", Double(result.summary.totalFiles) / duration))")
            print("   Lines per Second: \(String(format: "%.0f", Double(result.summary.totalLines) / duration))")
            
            // Performance quality assessment
            if duration < 10.0 {
                print("   üöÄ Excellent: Sub-10 second analysis")
            } else if duration < 20.0 {
                print("   ‚ö° Good: Sub-20 second analysis")
            } else {
                print("   ‚ö†Ô∏è Needs Optimization: Analysis could be faster")
            }
            
        } catch {
            #expect(Bool(false), "Performance test should not fail: \(error)")
        }
    }
}
